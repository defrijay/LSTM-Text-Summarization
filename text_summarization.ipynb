{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lkQsEvBqmjYr",
    "outputId": "85d35aa4-e63c-4542-a7bc-395820c417af"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'myenv (Python 3.12.7)' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '\"c:/Universitas Pendidikan Indonesia/COLLEGE/Semester 5/Natural Language Processing/Task2/Many-to-many/myenv/Scripts/python.exe\" -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tw25-ZJX70VG"
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# # Set direktori kerja ke folder yang berisi file Anda\n",
    "# os.chdir('/content/drive/My Drive/Colab Notebooks/Natural Language Processing/Task 2/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3rgcG-8O-QWn",
    "outputId": "2d60ea27-ebc7-45ca-de9a-63997479c815"
   },
   "outputs": [],
   "source": [
    "!pip install numpy pandas tensorflow nltk rouge-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZDsKhjND_O4U"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense, TimeDistributed, Masking\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "68gR0qxq_ESs",
    "outputId": "7bf770b5-9d0a-4fe2-fce8-f2b62c6a6fab"
   },
   "outputs": [],
   "source": [
    "# Memuat dataset\n",
    "df = pd.read_csv('liputan6.csv')\n",
    "df = df[['clean_article', 'clean_summary']]\n",
    "\n",
    "# Lihat contoh data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Jm-j6CAgmI2G",
    "outputId": "621d8c1f-a680-42c2-ad7b-eeb6d8af2a49"
   },
   "outputs": [],
   "source": [
    "# Menampilkan jumlah total data dalam dataset\n",
    "print(\"Total data dalam dataset:\", len(df))\n",
    "\n",
    "# Menampilkan jumlah data yang ada di setiap kolom 'clean_article' dan 'clean_summary'\n",
    "print(\"Total data di kolom 'clean_article':\", df['clean_article'].notnull().sum())\n",
    "print(\"Total data di kolom 'clean_summary':\", df['clean_summary'].notnull().sum())\n",
    "\n",
    "# Menjumlahkan total data non-null dari kedua kolom\n",
    "total_non_null = df['clean_article'].notnull().sum() + df['clean_summary'].notnull().sum()\n",
    "print(\"Total dari kedua kolom (clean_article dan clean_summary):\", total_non_null)\n",
    "\n",
    "# Menampilkan informasi jumlah kolom dan jenis data\n",
    "print(\"\\nInfo Dataset:\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sOLqInd7AmBD"
   },
   "outputs": [],
   "source": [
    "# Menggunakan Tokenizer untuk teks\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(df['clean_article'].tolist() + df['clean_summary'].tolist())\n",
    "\n",
    "# Konversi teks menjadi sequences\n",
    "input_sequences = tokenizer.texts_to_sequences(df['clean_article'].tolist())\n",
    "target_sequences = tokenizer.texts_to_sequences(df['clean_summary'].tolist())\n",
    "\n",
    "# Padding sequences untuk memastikan panjangnya seragam\n",
    "max_input_len = 500  # Batasi panjang maksimum input sequence\n",
    "max_target_len = 50  # Batasi panjang maksimum target sequence\n",
    "\n",
    "# Padding sequences untuk memastikan panjangnya seragam\n",
    "input_sequences = pad_sequences(input_sequences, maxlen=max_input_len, padding='post')\n",
    "target_sequences = pad_sequences(target_sequences, maxlen=max_target_len, padding='post')\n",
    "\n",
    "# Mendapatkan ukuran vocabulary\n",
    "vocab_size = len(tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o0TSJcbgA4NH",
    "outputId": "0e4604db-d7ad-4ac1-a995-16d58f9a9951"
   },
   "outputs": [],
   "source": [
    "# Periksa panjang input dan target sequences yang sudah diproses\n",
    "print(\"Panjang input sequences:\", max_input_len)\n",
    "print(\"Panjang target sequences:\", max_target_len)\n",
    "\n",
    "# Model dengan validasi\n",
    "X_train, X_val, y_train, y_val = train_test_split(input_sequences, target_sequences, test_size=0.2, random_state=42)\n",
    "\n",
    "# Menggunakan `max_input_len` untuk padding\n",
    "y_train = pad_sequences(y_train, maxlen=max_input_len, padding='post')\n",
    "y_val = pad_sequences(y_val, maxlen=max_input_len, padding='post')\n",
    "\n",
    "# Model\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_size, output_dim=64))\n",
    "model.add(SimpleRNN(64, return_sequences=True))\n",
    "model.add(TimeDistributed(Dense(vocab_size, activation='softmax')))\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Melatih model dengan validasi\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_val, y_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 314
    },
    "id": "cXooL8pnD_ej",
    "outputId": "30df34aa-3fe2-46e8-aaa2-c4db266f5726"
   },
   "outputs": [],
   "source": [
    "# Plotting Loss dan Accuracy\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], label='Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['accuracy'], label='Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G3Vub1QSLx1u",
    "outputId": "e3d0e324-3be7-4988-9e0c-6294163033b9"
   },
   "outputs": [],
   "source": [
    "def summarize_text(input_text):\n",
    "    # Proses teks input\n",
    "    input_seq = tokenizer.texts_to_sequences([input_text])\n",
    "    input_seq = pad_sequences(input_seq, maxlen=max_input_len, padding='post')\n",
    "\n",
    "    # Prediksi output\n",
    "    predicted_seq = model.predict(input_seq)\n",
    "    predicted_seq = np.argmax(predicted_seq, axis=-1)[0]  # Ambil indeks dengan probabilitas tertinggi\n",
    "\n",
    "    # Konversi output menjadi teks\n",
    "    summary = ' '.join(tokenizer.index_word[idx] for idx in predicted_seq if idx > 0)\n",
    "    return summary\n",
    "\n",
    "# Mengambil input dari pengguna dan menampilkan ringkasan\n",
    "input_text = input(\"Masukkan teks yang ingin diringkas: \")\n",
    "ringkasan = summarize_text(input_text)\n",
    "print(\"Ringkasan:\", ringkasan)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "gpuType": "V28",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
